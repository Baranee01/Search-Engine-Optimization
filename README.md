# Search Engine Optimization

### INSTALLATION

This project requires **Python** and the following Python libraries installed:

- [NumPy](http://www.numpy.org/)
- [Pandas](http://pandas.pydata.org)
- [matplotlib](http://matplotlib.org/)
- [scikit-learn](http://scikit-learn.org/stable/)
- [seaborn](http://seaborn.pydata.org/)

You will also need to have software installed to run and execute a [Jupyter Notebook](http://jupyter.org/index.html)

If you do not have Python installed yet, it is highly recommended that you install the [Anaconda](http://continuum.io/downloads) distribution of Python, which already has the above packages and more included.

##
### EXECUTION

In a terminal or command window, navigate to the top-level project directory `SearchEngineOptimization/` (that contains this README) and run one of the following commands:

```bash
jupyter notebook PROJECTSEO.ipynb
```
or
```bash
ipython notebook PROJECTSEO.ipynb
```

This will open the Jupyter Notebook software and project file in your web browser. You can also use Google Colab for easy access as it already has all the packages installed.

##
### ABOUT THE DATASET
The dataset used for analysis is the keywords selection data from the SEO keywords repository called E-Grow. In that dataset there are 500 keywords related to shoes. They include 21 attributes, 19 are numeric and “keyword” attribute alone is a string. This also includes a class attribute.

Source : EGrow Keywords Repository

Link : https://in.egrow.io/member/keyword-niche-tool

### SAMPLE DATASET
![image](https://user-images.githubusercontent.com/80042740/117948020-5fad6a00-b32e-11eb-9017-00afd89d8ed7.png)

##
### FLOW OF THE PROJECT
- Data Preprocessing.
- Exploratory Data Analysis.
- Splitting training and test data.
- Model Building.
- Results and Analysis.
